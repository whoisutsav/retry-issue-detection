org/apache/hadoop/hbase/CoordinatedStateManager.class;;;public interface org.apache.hadoop.hbase.CoordinatedStateManager {
  public abstract org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination getSplitLogWorkerCoordination();
  public abstract org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination getSplitLogManagerCoordination();
}
;;;No. This class is an interface that declares two abstract methods which return objects of other classes. It does not represent a message.;;;N;;;No.;;;N
org/apache/hadoop/hbase/ExecutorStatusChore.class;;;public class org.apache.hadoop.hbase.ExecutorStatusChore extends org.apache.hadoop.hbase.ScheduledChore {
  public static final java.lang.String WAKE_FREQ;
  public static final int DEFAULT_WAKE_FREQ;
  public org.apache.hadoop.hbase.ExecutorStatusChore(int, org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.hbase.executor.ExecutorService, org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource);
  public org.apache.hadoop.hbase.util.Pair<java.lang.Long, java.lang.Long> getExecutorStatus(java.lang.String);
}
;;;No.;;;N;;;Yes, it could be described as a task class.;;;Y
org/apache/hadoop/hbase/HBaseRpcServicesBase.class;;;public abstract class org.apache.hadoop.hbase.HBaseRpcServicesBase<S extends org.apache.hadoop.hbase.HBaseServerBase<?>> implements org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$ClientMetaService$BlockingInterface, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos$AdminService$BlockingInterface, org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler, org.apache.hadoop.hbase.ipc.PriorityFunction, org.apache.hadoop.hbase.conf.ConfigurationObserver {
  public static final java.lang.String CLIENT_BOOTSTRAP_NODE_LIMIT;
  public static final int DEFAULT_CLIENT_BOOTSTRAP_NODE_LIMIT;
  public org.apache.hadoop.hbase.security.access.AccessChecker getAccessChecker();
  public org.apache.hadoop.hbase.security.access.ZKPermissionWatcher getZkPermissionWatcher();
  public org.apache.hadoop.conf.Configuration getConfiguration();
  public S getServer();
  public java.net.InetSocketAddress getSocketAddress();
  public org.apache.hadoop.hbase.ipc.RpcServerInterface getRpcServer();
  public org.apache.hadoop.hbase.ipc.RpcScheduler getRpcScheduler();
  public int getPriority(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos$RequestHeader, org.apache.hbase.thirdparty.com.google.protobuf.Message, org.apache.hadoop.hbase.security.User);
  public long getDeadline(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos$RequestHeader, org.apache.hbase.thirdparty.com.google.protobuf.Message);
  public boolean checkOOME(java.lang.Throwable);
  public void onConfigurationChange(org.apache.hadoop.conf.Configuration);
  public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetClusterIdResponse getClusterId(org.apache.hbase.thirdparty.com.google.protobuf.RpcController, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetClusterIdRequest) throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
  public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetActiveMasterResponse getActiveMaster(org.apache.hbase.thirdparty.com.google.protobuf.RpcController, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetActiveMasterRequest) throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
  public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetMastersResponse getMasters(org.apache.hbase.thirdparty.com.google.protobuf.RpcController, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetMastersRequest) throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
  public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetMetaRegionLocationsResponse getMetaRegionLocations(org.apache.hbase.thirdparty.com.google.protobuf.RpcController, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetMetaRegionLocationsRequest) throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
  public final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetBootstrapNodesResponse getBootstrapNodes(org.apache.hbase.thirdparty.com.google.protobuf.RpcController, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos$GetBootstrapNodesRequest) throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
  public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos$UpdateConfigurationResponse updateConfiguration(org.apache.hbase.thirdparty.com.google.protobuf.RpcController, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos$UpdateConfigurationRequest) throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
  public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos$ClearSlowLogResponses clearSlowLogsResponses(org.apache.hbase.thirdparty.com.google.protobuf.RpcController, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos$ClearSlowLogResponseRequest) throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
  public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos$LogEntry getLogEntries(org.apache.hbase.thirdparty.com.google.protobuf.RpcController, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos$LogRequest) throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
}
;;;Yes.;;;Y;;;;;;N
org/apache/hadoop/hbase/HBaseServerBase.class;;;public abstract class org.apache.hadoop.hbase.HBaseServerBase<R extends org.apache.hadoop.hbase.HBaseRpcServicesBase<?>> extends java.lang.Thread implements org.apache.hadoop.hbase.Server, org.apache.hadoop.hbase.conf.ConfigurationObserver, org.apache.hadoop.hbase.client.ConnectionRegistryEndpoint {
  public org.apache.hadoop.hbase.HBaseServerBase(org.apache.hadoop.conf.Configuration, java.lang.String) throws java.io.IOException;
  public boolean isStopped();
  public boolean isAborted();
  public org.apache.hadoop.conf.Configuration getConfiguration();
  public org.apache.hadoop.hbase.client.AsyncClusterConnection getAsyncClusterConnection();
  public org.apache.hadoop.hbase.zookeeper.ZKWatcher getZooKeeper();
  public boolean isShutdownHookInstalled();
  public org.apache.hadoop.hbase.ServerName getServerName();
  public org.apache.hadoop.hbase.ChoreService getChoreService();
  public org.apache.hadoop.hbase.TableDescriptors getTableDescriptors();
  public org.apache.hadoop.hbase.executor.ExecutorService getExecutorService();
  public org.apache.hadoop.hbase.security.access.AccessChecker getAccessChecker();
  public org.apache.hadoop.hbase.security.access.ZKPermissionWatcher getZKPermissionWatcher();
  public org.apache.hadoop.hbase.CoordinatedStateManager getCoordinatedStateManager();
  public org.apache.hadoop.hbase.client.Connection createConnection(org.apache.hadoop.conf.Configuration) throws java.io.IOException;
  public org.apache.hadoop.fs.Path getDataRootDir();
  public org.apache.hadoop.fs.FileSystem getFileSystem();
  public org.apache.hadoop.fs.Path getWALRootDir();
  public org.apache.hadoop.fs.FileSystem getWALFileSystem();
  public boolean isClusterUp();
  public long getStartcode();
  public org.apache.hadoop.hbase.http.InfoServer getInfoServer();
  public int getMsgInterval();
  public org.apache.hadoop.hbase.namequeues.NamedQueueRecorder getNamedQueueRecorder();
  public org.apache.hadoop.hbase.ipc.RpcServerInterface getRpcServer();
  public org.apache.hadoop.hbase.util.NettyEventLoopGroupConfig getEventLoopGroupConfig();
  public R getRpcServices();
  public org.apache.hadoop.hbase.MetaRegionLocationCache getMetaRegionLocationCache();
  public void updateConfiguration();
  public java.lang.String toString();
}
;;;No. This class provides implementation details for a HBase server and does not represent a message.;;;N;;;No.;;;N
org/apache/hadoop/hbase/HealthCheckChore.class;;;public class org.apache.hadoop.hbase.HealthCheckChore extends org.apache.hadoop.hbase.ScheduledChore {
  public org.apache.hadoop.hbase.HealthCheckChore(int, org.apache.hadoop.hbase.Stoppable, org.apache.hadoop.conf.Configuration);
}
;;;No. This class extends another class and has a constructor with parameters, but it is not designed to represent or send a message. It is a chore class that performs health checks on an Apache HBase cluster.;;;N;;;Yes, it could be described as a task class, as it extends a ScheduledChore and has a constructor that takes in parameters for scheduling and stopping the task.;;;Y
org/apache/hadoop/hbase/HealthChecker$1.class;;;class org.apache.hadoop.hbase.HealthChecker$1 {
}
;;;No.;;;N;;;No.;;;N
org/apache/hadoop/hbase/HealthChecker$HealthCheckerExitStatus.class;;;final class org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus extends java.lang.Enum<org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus> {
  public static final org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus SUCCESS;
  public static final org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus TIMED_OUT;
  public static final org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus FAILED_WITH_EXIT_CODE;
  public static final org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus FAILED_WITH_EXCEPTION;
  public static final org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus FAILED;
  public static org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus[] values();
  public static org.apache.hadoop.hbase.HealthChecker$HealthCheckerExitStatus valueOf(java.lang.String);
}
;;;No. It is an enum class with constants representing different exit statuses for a health checker, but it does not define or send any messages.;;;N;;;No. It is an enumeration class that defines different exit statuses for a health checker in the Apache HBase library. It does not represent a task or any specific functionality that needs to be executed.;;;N
org/apache/hadoop/hbase/HealthChecker.class;;;class org.apache.hadoop.hbase.HealthChecker {
  public void init(java.lang.String, long);
  public org.apache.hadoop.hbase.HealthReport checkHealth();
}
;;;Yes.;;;Y;;;;;;N
org/apache/hadoop/hbase/HealthReport.class;;;class org.apache.hadoop.hbase.HealthReport {
  public java.lang.String toString();
  public int hashCode();
  public boolean equals(java.lang.Object);
}
;;;No.;;;N;;;No.;;;N
org/apache/hadoop/hbase/JMXListener.class;;;public class org.apache.hadoop.hbase.JMXListener implements org.apache.hadoop.hbase.coprocessor.MasterCoprocessor,org.apache.hadoop.hbase.coprocessor.RegionServerCoprocessor {
  public static final java.lang.String RMI_REGISTRY_PORT_CONF_KEY;
  public static final java.lang.String RMI_CONNECTOR_PORT_CONF_KEY;
  public static final int defMasterRMIRegistryPort;
  public static final int defRegionserverRMIRegistryPort;
  public org.apache.hadoop.hbase.JMXListener();
  public static javax.management.remote.JMXServiceURL buildJMXServiceURL(int, int) throws java.io.IOException;
  public void startConnectorServer(int, int) throws java.io.IOException;
  public void stopConnectorServer() throws java.io.IOException;
  public void start(org.apache.hadoop.hbase.CoprocessorEnvironment) throws java.io.IOException;
  public void stop(org.apache.hadoop.hbase.CoprocessorEnvironment) throws java.io.IOException;
}
;;;No, it is not a message class. It is a class that implements two interfaces related to Hadoop HBase coprocessors and provides methods for starting and stopping JMX connector server.;;;N;;;No.;;;N
org/apache/hadoop/hbase/LocalHBaseCluster$1.class;;;class org.apache.hadoop.hbase.LocalHBaseCluster$1 implements java.security.PrivilegedExceptionAction<org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread> {
  public org.apache.hadoop.hbase.util.JVMClusterUtil$RegionServerThread run() throws java.lang.Exception;
  public java.lang.Object run() throws java.lang.Exception;
}
;;;No.;;;N;;;No. It appears to be an anonymous inner class that implements the java.security.PrivilegedExceptionAction interface with two run() methods. Without additional context, it is difficult to determine its specific purpose, but it does not appear to be specifically designed as a message class or a task class.;;;N
org/apache/hadoop/hbase/LocalHBaseCluster$2.class;;;class org.apache.hadoop.hbase.LocalHBaseCluster$2 implements java.security.PrivilegedExceptionAction<org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread> {
  public org.apache.hadoop.hbase.util.JVMClusterUtil$MasterThread run() throws java.lang.Exception;
  public java.lang.Object run() throws java.lang.Exception;
}
;;;No.;;;N;;;No.;;;N
